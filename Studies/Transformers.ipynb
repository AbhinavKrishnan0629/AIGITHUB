{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb42d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42cf0cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "\n",
      "CuDNN is enabled: True\n",
      "\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] \n",
      "\n",
      "Num GPUs Available:  1 \n",
      "\n",
      "GPU Name:  /device:GPU:0 \n",
      "\n",
      "Available devices:  ['/device:CPU:0', '/device:GPU:0'] \n",
      "\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\\n\")\n",
    "    print(\"CuDNN is enabled: True\\n\")\n",
    "else:\n",
    "    print(\"GPU is not available\\n\")\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'), \"\\n\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')), \"\\n\")\n",
    "print(\"GPU Name: \", tf.test.gpu_device_name(), \"\\n\")\n",
    "\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(\"Available devices: \", get_available_devices(), \"\\n\")\n",
    "\n",
    "devices_available = get_available_devices()\n",
    "print(devices_available[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa7d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "febf73a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of replicas:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "with tf.device(devices_available[1]):\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "    try:\n",
    "        # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "        # set: this is always the case on Kaggle.\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    else:\n",
    "        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "\n",
    "    print(\"Num of replicas: \", strategy.num_replicas_in_sync)\n",
    "#tf.distribute.get_strategy().num_replicas_in_sync equals 1,\n",
    "# it means that the training is not distributed and is being performed on a single device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401528e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train      = pd.read_csv(\"A:/Programming/Python/Data/AI_DOCTOR/Transformers_study/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")\n",
    "validation = pd.read_csv(\"A:/Programming/Python/Data/AI_DOCTOR/Transformers_study/jigsaw-multilingual-toxic-comment-classification/validation.csv\")\n",
    "test       = pd.read_csv(\"A:/Programming/Python/Data/AI_DOCTOR/Transformers_study/jigsaw-multilingual-toxic-comment-classification/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3d24f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  8\n",
      "id, comment_text, toxic, severe_toxic, obscene, threat, insult, identity_hate, \n",
      "Number of rows:  223549\n",
      "Number of columns:  4\n",
      "id, comment_text, lang, toxic, \n",
      "Number of rows:  8000\n",
      "Number of columns:  3\n",
      "id, content, lang, \n",
      "Number of rows:  63812\n"
     ]
    }
   ],
   "source": [
    "for i in [train, validation, test]:\n",
    "    shape = i.shape\n",
    "    ncols = shape[1]\n",
    "    nrows = shape[0]\n",
    "    print(\"Number of columns: \", ncols)\n",
    "    for j in i.columns:\n",
    "        print(j, end=\", \")\n",
    "    print(\"\\nNumber of rows: \", nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae24511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6812c011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12001, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.loc[:12000,:]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94e15a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945db6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1403"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Max number of words that is possible in column comment_text\n",
    "train['comment_text'].apply(lambda x: len(str(x).split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "585bc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(predictions, target):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
    "    roc_auc_score = metrics.auc(fpr, tpr)\n",
    "    return roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96390f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values, \n",
    "                                                  stratify=train.toxic.values, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd94075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2cab960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "612327cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2de071e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token.fit_on_texts(list(xtrain)+list(xvalid))\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "xtrain_pad = pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad823f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa4930d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
